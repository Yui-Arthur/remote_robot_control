{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "def expand_row_data(data, capture_point) -> tuple[np.ndarray, np.ndarray]:\n",
    "\n",
    "    label = []\n",
    "    expand_data = []\n",
    "\n",
    "    for idx in range(1, len(data), capture_point):\n",
    "        label.append(int(data[0]))\n",
    "        expand_data.append(np.array(data[idx : idx + capture_point]))\n",
    "\n",
    "    return label, expand_data\n",
    "\n",
    "def gen_tf_dataset(data, capture_point, batch_size, output_class):\n",
    "    label = []\n",
    "    expanded_data = []\n",
    "    for row in data:\n",
    "        l, e = expand_row_data(row, capture_point)    \n",
    "        \n",
    "        label += l\n",
    "        expanded_data += e\n",
    "    label = tf.one_hot(label, output_class)  \n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((expanded_data, label))\n",
    "    dataset = dataset.shuffle(len(data), reshuffle_each_iteration=True)\n",
    "    dataset = dataset.cache()\n",
    "    dataset = dataset.batch(batch_size, drop_remainder=True).prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "def dataset_preproccessed(data_folder, batch_size, train_vaild_test_ratio, output_class):\n",
    "    data_folder = Path(data_folder)\n",
    "    capture_point, extra_point = data_folder.stem.split('_')[:-1]\n",
    "    capture_point = int(capture_point[1:])\n",
    "    extra_point = int(extra_point[1:])\n",
    "\n",
    "    \n",
    "    with open(data_folder, newline='') as data:\n",
    "        row_data = csv.reader(data, delimiter=',')\n",
    "        row_data = [i for i in row_data]\n",
    "\n",
    "    random.shuffle(row_data)\n",
    "    \n",
    "    train_data_cnt = int(len(row_data) * train_vaild_test_ratio[0])\n",
    "    valid_data_cnt = int(len(row_data) * train_vaild_test_ratio[1])\n",
    "    test_data_cnt = len(row_data) - train_data_cnt - valid_data_cnt\n",
    "    print(capture_point, extra_point)\n",
    "    print(train_data_cnt, valid_data_cnt, test_data_cnt)\n",
    "    \n",
    "    for idx, row in enumerate(row_data):\n",
    "        for c_idx, _ in enumerate(row): row[c_idx] = int(row[c_idx])\n",
    "\n",
    "    train_dataset = gen_tf_dataset(row_data[:train_data_cnt], capture_point, batch_size, output_class)\n",
    "    valid_dataset = gen_tf_dataset(row_data[train_data_cnt : train_data_cnt + valid_data_cnt], capture_point, batch_size, output_class)\n",
    "    test_dataset = gen_tf_dataset(row_data[train_data_cnt + valid_data_cnt : ], capture_point, batch_size, output_class)\n",
    "    \n",
    "    return capture_point, train_dataset, valid_dataset, test_dataset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pseudo dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_pseudo_dataset(size, capture_point, batch_size, output_class):\n",
    "    label = []\n",
    "    expanded_data = []\n",
    "\n",
    "    x_values = np.random.uniform(low=0, high= output_class * 1000, size=size).astype(np.float32)\n",
    "\n",
    "    for x in x_values:\n",
    "        l = int(x // 1000) \n",
    "\n",
    "        e = [l for i in range(capture_point)]\n",
    "\n",
    "        label += [l]\n",
    "        expanded_data += [e]\n",
    "    label = tf.one_hot(label, output_class)  \n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((expanded_data, label))\n",
    "    dataset = dataset.shuffle(size, reshuffle_each_iteration=True)\n",
    "    dataset = dataset.cache()\n",
    "    dataset = dataset.batch(batch_size, drop_remainder=True).prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "def pseudo_dataset_preproccessed(total_data_size ,capture_point, batch_size, train_vaild_test_ratio, output_class):\n",
    "\n",
    "    \n",
    "    train_data_cnt = int(total_data_size * train_vaild_test_ratio[0])\n",
    "    valid_data_cnt = int(total_data_size * train_vaild_test_ratio[1])\n",
    "    test_data_cnt = total_data_size- train_data_cnt - valid_data_cnt\n",
    "    print(capture_point)\n",
    "    print(train_data_cnt, valid_data_cnt, test_data_cnt)\n",
    "\n",
    "    train_dataset = gen_pseudo_dataset(train_data_cnt, capture_point, batch_size, output_class)\n",
    "    valid_dataset = gen_pseudo_dataset(valid_data_cnt, capture_point, batch_size, output_class)\n",
    "    test_dataset = gen_pseudo_dataset(test_data_cnt, capture_point, batch_size, output_class)\n",
    "    \n",
    "    return capture_point, train_dataset, valid_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model(tf.keras.Model):\n",
    "    def __init__(self , input_dim , out_class = 9 , learning_rate=1e-3):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.out_class = out_class\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        self._model = self._build_model()\n",
    "        self._learner = self._build_learner()\n",
    "    \n",
    "    @tf.function\n",
    "    def call(self, x:tf.Tensor, training:bool=False) -> tf.Tensor:\n",
    "        output = self._model(x, training=training)\n",
    "        return output\n",
    "    \n",
    "    @tf.function\n",
    "    def train(self, x:tf.Tensor, y:tf.Tensor):\n",
    "        with tf.GradientTape() as tape:\n",
    "            output = self.__call__(x, training=True)\n",
    "            classLoss = self._learner[\"get_loss\"](y, output)\n",
    "            review = tf.math.in_top_k(tf.math.argmax(y,axis=1), output, 1)\n",
    "            perf = tf.math.reduce_mean(tf.cast(review, dtype=\"float32\"))\n",
    "\n",
    "        cGradients = tape.gradient(classLoss, self._model.trainable_variables)\n",
    "        self._learner[\"optimize\"].apply_gradients(zip(cGradients, self._model.trainable_variables))\n",
    "        return perf, classLoss\n",
    "\n",
    "\n",
    "    @tf.function\n",
    "    def validate(self, x:tf.Tensor, y:tf.Tensor) -> tf.Tensor:\n",
    "        output = self.__call__(x, training=False)\n",
    "        classLoss = self._learner[\"get_loss\"](y , output)\n",
    "        review = tf.math.in_top_k(tf.math.argmax(y,axis=1), output, 1)\n",
    "        perf = tf.math.reduce_mean(tf.cast(review, dtype=\"float32\"))\n",
    "        return perf , classLoss\n",
    "\n",
    "    def _build_model(self) -> tf.keras.Model:\n",
    "\n",
    "        input_tensor = tf.keras.Input(shape=self.input_dim)\n",
    "        feature_map = input_tensor\n",
    "        \n",
    "        d = 32\n",
    "        feature_map = tf.keras.layers.Dense(d, input_dim = self.input_dim, activation='relu')(feature_map)\n",
    "        # feature_map = tf.keras.layers.Dropout(0.2)(feature_map)\n",
    "        # feature_map = tf.keras.layers.Dense(d, input_dim = d, activation='relu')(feature_map)\n",
    "        # feature_map = tf.keras.layers.Dropout(0.2)(feature_map)\n",
    "        # feature_map = tf.keras.layers.Dense(512, input_dim = 512, activation='relu')(feature_map)\n",
    "        output_tensor = tf.keras.layers.Dense(self.out_class, input_dim = d, activation=tf.keras.activations.softmax)(feature_map)\n",
    "        \n",
    "\n",
    "        model = tf.keras.Model(input_tensor, output_tensor)\n",
    "        return model\n",
    "    \n",
    "    def _build_learner(self) -> dict:\n",
    "        # classLoss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "        classLoss = tf.keras.losses.CategoricalCrossentropy()\n",
    "        classOptimizer = tf.keras.optimizers.Adam(learning_rate=self.learning_rate)\n",
    "        learner = {\"get_loss\": classLoss, \"optimize\": classOptimizer}\n",
    "\n",
    "        return learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model , train_dataloader , valid_dataloader , max_acc , root_dir : Path):\n",
    "\n",
    "    epoch_train_loss = []\n",
    "    epoch_train_acc = []\n",
    "    epoch_valid_loss = []\n",
    "    epoch_valid_acc = []\n",
    "\n",
    "    for inData, outData in tqdm(train_dataloader):\n",
    "        acc , loss = model.train(inData, outData)\n",
    "        epoch_train_acc.append(acc)\n",
    "        epoch_train_loss.append(loss)\n",
    "        # print(loss)\n",
    "        # print(acc)\n",
    "    # raise ValueError\n",
    "        \n",
    "    for inData, outData in tqdm(valid_dataloader):\n",
    "        acc , loss = model.validate(inData, outData)\n",
    "        epoch_valid_acc.append(acc)\n",
    "        epoch_valid_loss.append(loss)\n",
    "\n",
    "    epoch_train_acc_mean = tf.math.reduce_mean(epoch_train_acc) * 100\n",
    "    epoch_valid_acc_mean = tf.math.reduce_mean(epoch_valid_acc) * 100\n",
    "    epoch_train_loss_mean = tf.math.reduce_mean(epoch_train_loss)\n",
    "    epoch_valid_loss_mean = tf.math.reduce_mean(epoch_valid_loss)\n",
    "\n",
    "    print(f\"  Train Acc: {epoch_train_acc_mean:.2f}, Loss: {epoch_train_loss_mean:.2f}\")\n",
    "    print(f\"  Valid Acc: {epoch_valid_acc_mean:.2f}, Loss: {epoch_valid_loss_mean:.2f}\")\n",
    "\n",
    "    if(epoch_valid_acc_mean > max_acc):\n",
    "        print(\"save best model\")\n",
    "        model.save(root_dir /\"model\", include_optimizer=False)\n",
    "    \n",
    "    return epoch_train_acc_mean, epoch_train_loss_mean , epoch_valid_acc_mean , epoch_valid_loss_mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing_model(test_dataloader , root_dir : Path = None , model_path : Path = None):\n",
    "    if root_dir is not None :\n",
    "        model = tf.keras.models.load_model(root_dir / \"model\", compile=False)\n",
    "    elif model_path is not None:\n",
    "        model = tf.keras.models.load_model(model_path)\n",
    "    else:\n",
    "        raise AttributeError(\"Testing models root_dir and model_path are not given\")\n",
    "    \n",
    "    testing_acc = []\n",
    "    print(\"Testing Model\")\n",
    "    \n",
    "    for data , label in tqdm(test_dataloader):\n",
    "        acc , loss = model.validate(data , label)\n",
    "        \n",
    "        testing_acc.append(acc)\n",
    "    \n",
    "    print(f\"acc = {np.mean(testing_acc)*100:.2f}\")\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_train_results(train_info , root_folder : Path):\n",
    "    train_info = np.array(train_info)\n",
    "\n",
    "    plt.plot(np.arange(1,train_info.shape[0]+1) , train_info[:,0] , 'r' , label='train')\n",
    "    plt.plot(np.arange(1,train_info.shape[0]+1) , train_info[:,2] , 'b' , label='valid')\n",
    "    plt.title(\"Acc\")\n",
    "    plt.savefig(root_folder / \"model\" / \"Acc.png\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(np.arange(1,train_info.shape[0]+1) , train_info[:,1] , 'r' , label='train')\n",
    "    plt.plot(np.arange(1,train_info.shape[0]+1) , train_info[:,3] , 'b' , label='valid')\n",
    "    plt.title(\"Loss\")\n",
    "    plt.savefig(root_folder / \"model\" / \"Loss.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_tflite_quant(save_model_folder : Path , dataset):\n",
    "\n",
    "    def representative_dataset():\n",
    "        idx = 0\n",
    "        for data , label in dataset:\n",
    "            # if idx > 1000:\n",
    "            #     break\n",
    "            # idx += 1\n",
    "            \n",
    "            yield [data]\n",
    "\n",
    "    # float\n",
    "    converter = tf.lite.TFLiteConverter.from_saved_model(str(save_model_folder))\n",
    "    tflite_model = converter.convert()\n",
    "    open(save_model_folder / 'float_model.tflite', 'wb').write(tflite_model)\n",
    "    print(\"Successfully convert tflite float\")\n",
    "\n",
    "    # quant\n",
    "    converter = tf.lite.TFLiteConverter.from_saved_model(str(save_model_folder))\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    converter.representative_dataset = representative_dataset\n",
    "    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "    converter.inference_input_type = tf.int8  # or tf.uint8\n",
    "    converter.inference_output_type = tf.int8  # or tf.uint8\n",
    "    tflite_quant_model = converter.convert()\n",
    "    open(save_model_folder / 'quant_model.tflite', 'wb').write(tflite_quant_model)\n",
    "    print(\"Successfully convert tflite quant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_tflite_model(tflite_model_path, test_dataset):\n",
    "    interpreter = tf.lite.Interpreter(model_path=str(tflite_model_path))\n",
    "    interpreter.allocate_tensors()\n",
    "    input = interpreter.get_input_details()[0]\n",
    "    output = interpreter.get_output_details()[0]\n",
    "    input_scale, input_zero_point = input['quantization']\n",
    "    output_scale, output_zero_point = output[\"quantization\"]\n",
    "    \n",
    "    print(f\"testing with {tflite_model_path}\")\n",
    "    \n",
    "    testing_acc = np.array([])\n",
    "    for data , label in tqdm(test_dataset):\n",
    "        if input[\"dtype\"] == np.float32:\n",
    "            interpreter.set_tensor(input['index'], data)\n",
    "        else:\n",
    "            quant_data = data.numpy() / input_scale + input_zero_point\n",
    "            interpreter.set_tensor(input['index'], quant_data.astype(input[\"dtype\"] ))\n",
    "\n",
    "        interpreter.invoke()\n",
    "\n",
    "        if output[\"dtype\"] == np.float32:\n",
    "            pred = interpreter.get_tensor(output['index'])\n",
    "        else:\n",
    "            dequant_pred = interpreter.get_tensor(output['index']).astype(np.float32)\n",
    "            pred = (dequant_pred - output_zero_point) * output_scale\n",
    "\n",
    "        testing_acc = np.append(testing_acc, np.argmax(pred) == np.argmax(label))   \n",
    "    \n",
    "    print(f\"result acc = {np.mean(testing_acc)*100:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "2700 150 150\n",
      "Model: \"model_159\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_80 (InputLayer)       [(None, 15)]              0         \n",
      "                                                                 \n",
      " dense_191 (Dense)           (None, 32)                512       \n",
      "                                                                 \n",
      " dense_192 (Dense)           (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 842 (3.29 KB)\n",
      "Trainable params: 842 (3.29 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:00<00:00, 83.30it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 28.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Acc: 10.23, Loss: 3.10\n",
      "  Valid Acc: 7.81, Loss: 2.25\n",
      "save best model\n",
      "INFO:tensorflow:Assets written to: model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/assets\n",
      "100%|██████████| 42/42 [00:00<00:00, 826.03it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 500.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Acc: 10.27, Loss: 2.18\n",
      "  Valid Acc: 14.06, Loss: 2.07\n",
      "save best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/assets\n",
      "100%|██████████| 42/42 [00:00<00:00, 832.49it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 556.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Acc: 9.78, Loss: 2.11\n",
      "  Valid Acc: 14.06, Loss: 2.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:00<00:00, 794.84it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 491.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Acc: 9.97, Loss: 2.09\n",
      "  Valid Acc: 14.06, Loss: 2.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:00<00:00, 807.12it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 498.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Acc: 9.97, Loss: 2.07\n",
      "  Valid Acc: 14.06, Loss: 2.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:00<00:00, 815.39it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 524.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Acc: 10.04, Loss: 2.05\n",
      "  Valid Acc: 14.06, Loss: 2.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:00<00:00, 803.68it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 517.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Acc: 9.93, Loss: 2.03\n",
      "  Valid Acc: 14.06, Loss: 1.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:00<00:00, 808.91it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 492.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Acc: 9.93, Loss: 2.01\n",
      "  Valid Acc: 14.06, Loss: 1.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:00<00:00, 820.07it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 477.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Acc: 10.23, Loss: 2.00\n",
      "  Valid Acc: 14.06, Loss: 1.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:00<00:00, 829.97it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 523.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Acc: 10.04, Loss: 1.98\n",
      "  Valid Acc: 14.06, Loss: 1.93\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Importing a function (__inference_internal_grad_fn_942315) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 48.78it/s]\n",
      "WARNING:absl:Importing a function (__inference_internal_grad_fn_942315) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc = 8.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-01 22:47:20.361682: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-06-01 22:47:20.361715: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-06-01 22:47:20.361949: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: model\n",
      "2024-06-01 22:47:20.364209: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-06-01 22:47:20.364226: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: model\n",
      "2024-06-01 22:47:20.369153: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-06-01 22:47:20.403915: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: model\n",
      "2024-06-01 22:47:20.417447: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 55499 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 4, Total Ops 11, % non-converted = 36.36 %\n",
      " * 4 ARITH ops\n",
      "\n",
      "- arith.constant:    4 occurrences  (f32: 4)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 1)\n",
      "  (f32: 2)\n",
      "  (f32: 1)\n",
      "WARNING:absl:Importing a function (__inference_internal_grad_fn_942315) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully convert tflite float\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-01 22:47:20.835116: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-06-01 22:47:20.835145: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-06-01 22:47:20.835366: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: model\n",
      "2024-06-01 22:47:20.837492: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-06-01 22:47:20.837510: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: model\n",
      "2024-06-01 22:47:20.842315: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-06-01 22:47:20.876763: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: model\n",
      "2024-06-01 22:47:20.890107: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 54741 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 4, Total Ops 11, % non-converted = 36.36 %\n",
      " * 4 ARITH ops\n",
      "\n",
      "- arith.constant:    4 occurrences  (f32: 4)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 1)\n",
      "  (f32: 2)\n",
      "  (f32: 1)\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: INT8, output_inference_type: INT8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully convert tflite quant\n",
      "15\n",
      "10 10 980\n",
      "testing with model/float_model.tflite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/980 [00:00<?, ?it/s]/tmp/ipykernel_20426/139571656.py:16: RuntimeWarning: divide by zero encountered in divide\n",
      "  quant_data = data.numpy() / input_scale + input_zero_point\n",
      "/tmp/ipykernel_20426/139571656.py:17: RuntimeWarning: invalid value encountered in cast\n",
      "  interpreter.set_tensor(input['index'], quant_data.astype(input[\"dtype\"] ))\n",
      "/tmp/ipykernel_20426/139571656.py:16: RuntimeWarning: invalid value encountered in divide\n",
      "  quant_data = data.numpy() / input_scale + input_zero_point\n",
      "100%|██████████| 980/980 [00:00<00:00, 2750.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result acc = 8.06\n",
      "testing with model/quant_model.tflite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 980/980 [00:00<00:00, 2692.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result acc = 10.61\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "learning_rate = 1e-3\n",
    "epochs = 10\n",
    "\n",
    "output_class = 10\n",
    "save_dir = Path(\"./\")\n",
    "# input_shape, train_dataset, valid_dataset, test_dataset = dataset_preproccessed(\"../c3_e3_dataset.csv\", batch_size, [0.9, 0.05, 0.05], output_class)\n",
    "input_shape, train_dataset, valid_dataset, test_dataset = pseudo_dataset_preproccessed(3000, 15, batch_size, [0.9, 0.05, 0.05], output_class)\n",
    "\n",
    "m = model([input_shape], output_class, learning_rate)\n",
    "m.build((batch_size , input_shape))\n",
    "m._model.summary()\n",
    "\n",
    "train_info = []\n",
    "max_acc = 0\n",
    "for epoch in range(epochs):\n",
    "    epoch_info = train_one_epoch(m, train_dataset, valid_dataset, max_acc, save_dir)\n",
    "    max_acc = max(epoch_info[2], max_acc)\n",
    "    train_info.append(list(epoch_info))\n",
    "\n",
    "show_train_results(train_info , save_dir)\n",
    "testing_model(test_dataset, save_dir, save_dir)\n",
    "save_model_tflite_quant(save_dir / \"model\", valid_dataset)\n",
    "\n",
    "input_shape, train_dataset, valid_dataset, test_dataset = pseudo_dataset_preproccessed(1000, 15, 1, [0.01, 0.01, 0.98], output_class)\n",
    "test_tflite_model(save_dir / \"model\" / \"float_model.tflite\", test_dataset)\n",
    "test_tflite_model(save_dir / \"model\" / \"quant_model.tflite\", test_dataset)\n",
    "\n",
    "!xxd -i {save_dir}/model/quant_model.tflite > model/model.cc\n",
    "!echo -ne \"#include \\\"model_data_quant.h\\\"\\nalignas(8)\\n\" > model/model_data_quant.cc\n",
    "!cat model/model.cc >> model/model_data_quant.cc\n",
    "!sed -i -E 's/(unsigned\\s.*\\s).*(_len|\\[\\])/const \\1model\\2/g' model/model_data_quant.cc\n",
    "     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "umamba",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
